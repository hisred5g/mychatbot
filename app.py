import os
from dotenv import load_dotenv
import streamlit as st
from google import genai
from google.genai import types

load_dotenv()

SYSTEM_PROMPT = "ë„ˆëŠ” íŒŒì´ì¬ ê°œë°œìì•¼. ì½”ë”©ì— ê´€ë ¨ëœ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ì§€"

st.set_page_config(page_title="Gemini Chatbot", page_icon="ğŸ’¬")
st.title("ğŸ’¬ íŒŒì´ì¬ ê°€ì´ë“œ ì±—ë´‡")

# â”€â”€ ì„¸ì…˜ ìƒíƒœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    # role: "user" | "assistant", content: str
    st.session_state.messages = []

# â”€â”€ ìƒë‹¨: ëŒ€í™” ì „ì²´ ì´ˆê¸°í™” ë²„íŠ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
top_cols = st.columns([1, 6, 1])
with top_cols[0]:
    if st.button("ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# â”€â”€ ë§í’ì„  ìŠ¤íƒ€ì¼(CSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    """
    <style>
      .chat-wrap { width: 100%; }
      .chat-row { display: flex; margin: 8px 0; }
      .chat-row.user { justify-content: flex-end; }
      .chat-row.ai   { justify-content: flex-start; }
      .bubble {
        max-width: 80%;
        padding: 12px 14px;
        border-radius: 18px;
        line-height: 1.55;
        word-wrap: break-word;
        white-space: pre-wrap;
        box-shadow: 0 1px 2px rgba(0,0,0,0.08);
        font-size: 16px;
      }
      .bubble.user {
        background: #DCF8C6;     /* user: ì—°ë‘ìƒ‰ */
        border-top-right-radius: 6px;
      }
      .bubble.ai {
        background: #F1F0F0;     /* ai: íšŒìƒ‰ */
        border-top-left-radius: 6px;
      }
      .name {
        font-size: 12px; opacity: 0.6; margin-bottom: 4px;
      }
      .container { margin-top: 6px; }
    </style>
    """,
    unsafe_allow_html=True,
)

# â”€â”€ íˆìŠ¤í† ë¦¬(ë§í’ì„ ) ë Œë”ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown('<div class="chat-wrap">', unsafe_allow_html=True)
for m in st.session_state.messages:
    role_class = "user" if m["role"] == "user" else "ai"
    name = "ë‚˜" if m["role"] == "user" else "AI"
    # ê°„ë‹¨í•œ HTML ë Œë”(ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ í•„ìš” ì‹œ st.markdown ë³‘í–‰ ê°€ëŠ¥)
    html = f"""
    <div class="chat-row {role_class}">
      <div class="bubble {role_class}">
        <div class="name">{name}</div>
        {m['content']}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# â”€â”€ í”„ë¡¬í”„íŠ¸ ë¹Œë”(ì‹œìŠ¤í…œ+íˆìŠ¤í† ë¦¬+í˜„ì¬ì…ë ¥ í…ìŠ¤íŠ¸ë¡œ í†µí•©) â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt(messages, user_text):
    history_txt = ""
    for msg in messages:
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
        history_txt += f"{role}: {msg['content']}\n"
    return (
        f"[ì‹œìŠ¤í…œ]\n{SYSTEM_PROMPT}\n\n"
        f"[ëŒ€í™”]\n{history_txt}"
        f"ì‚¬ìš©ì: {user_text}\nAI:"
    )

# â”€â”€ ì…ë ¥(í•˜ë‹¨ ê³ ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")

# â”€â”€ ë©”ì‹œì§€ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if user_input is not None:
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡
    st.session_state.messages.append({"role": "user", "content": user_input})

    try:
        client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

        # 4) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = build_prompt(st.session_state.messages[:-1], user_input)

        # 5) ëª¨ë¸ í˜¸ì¶œ (google-genaiëŠ” config=GenerateContentConfig ë¡œ ì „ë‹¬)
        resp = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7, 
            ),
        )
        answer = getattr(resp, "text", "") or "(ë¹ˆ ì‘ë‹µ)"

        # 6) AI ì‘ë‹µ ê¸°ë¡ & ì¦‰ì‹œ ê°±ì‹ 
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.rerun()

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
